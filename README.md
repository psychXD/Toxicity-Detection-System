# Project: Toxicity Detection Benchmarking with OpenAssistant and LLaMA-2
Trained a Bert based model and T5 based Model 
This repository contains the implementation of benchmarking generative and discriminative large language models (LLMs) for toxicity detection. 
The primary models used  will be  LLaMA-2. // under progress
The aim is to evaluate their performance using metrics such as accuracy, precision, recall, and F1-score on a labeled dataset.

## Features
- Loading and inference using OpenAssistant/oasst-sft and LLaMA-2.
- Toxicity classification and benchmark testing.
- Performance evaluation with various metrics.

## Results 
- Classification accuracy
- Precision, recall, and F1-score

## Contributing
Feel free to open issues or submit pull requests to improve this repository.

---
